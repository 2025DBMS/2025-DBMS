from transformers import CLIPProcessor, CLIPModel
from PIL import Image
import requests
import torch
import psycopg2
import os
from dotenv import load_dotenv
from psycopg2.extras import RealDictCursor

# è®€å– .env æª”æ¡ˆ
load_dotenv()
DATABASE_URL = os.getenv("DATABASE_URL")

# ========== 1. å»ºç«‹ DB é€£ç·š ==========
conn = psycopg2.connect(DATABASE_URL)
cur = conn.cursor(cursor_factory=RealDictCursor)

# ========== 2. å»ºç«‹ listing æè¿° ==========
def generate_listing_texts(cur, conn):
    facility_labels = {
        "has_tv": "é›»è¦–", "has_aircon": "å†·æ°£", "has_fridge": "å†°ç®±",
        "has_washing": "æ´—è¡£æ©Ÿ", "has_heater": "ç†±æ°´å™¨", "has_bed": "åºŠ",
        "has_wardrobe": "è¡£æ«ƒ", "has_cable_tv": "æœ‰ç·šé›»è¦–", "has_internet": "ç¶²è·¯",
        "has_gas": "å¤©ç„¶æ°£", "has_sofa": "æ²™ç™¼", "has_table": "æ¡Œæ¤…",
        "has_balcony": "é™½å°", "has_elevator": "é›»æ¢¯", "has_parking": "åœè»Šä½"
    }

    cur.execute("""
        SELECT 
            l.id, l.title, l.price, l.deposit, l.city, l.district, l.address,
            l.building_type, l.layout, l.area, l.floor, l.available_from, l.url,
            lf.*
        FROM listings l
        LEFT JOIN listing_facilities lf ON l.id = lf.listing_id
    """)
    rows = cur.fetchall()

    print(f"Found {len(rows)} listings.")

    for row in rows:
        listing_desc = f"æ¨™é¡Œï¼š{row['title']}ï¼Œç§Ÿé‡‘ï¼š{row['price']} å…ƒï¼ŒæŠ¼é‡‘ï¼š{row['deposit']}ï¼ŒåŸå¸‚ï¼š{row['city']}ï¼Œ"
        listing_desc += f"{row['district']}ï¼Œåœ°å€ï¼š{row['address']}ï¼Œå»ºç¯‰å‹æ…‹ï¼š{row['building_type']}ï¼Œæ ¼å±€ï¼š{row['layout']}ï¼Œ"
        listing_desc += f"åªæ•¸ï¼š{row['area']} åªï¼Œæ¨“å±¤ï¼š{row['floor']}ï¼Œèµ·ç§Ÿæ—¥ï¼š{row['available_from']}ï¼Œç¶²å€ï¼š{row['url']}"

        facility_desc = []
        for key, label in facility_labels.items():
            if key in row:
                has_item = row[key]
                if has_item:
                    facility_desc.append(f"æœ‰{label}")
                else:
                    facility_desc.append(f"ç„¡{label}")
        facility_desc_str = "ã€".join(facility_desc)

        cur.execute("""
            INSERT INTO listings_embeddings (listing_id, listing_desc, facility_desc)
            VALUES (%s, %s, %s)
            ON CONFLICT (listing_id) DO UPDATE
            SET listing_desc = EXCLUDED.listing_desc,
                facility_desc = EXCLUDED.facility_desc
        """, (row['id'], listing_desc, facility_desc_str))

    conn.commit()
    print("âœ… listings_embeddings æè¿°å·²æ›´æ–°å®Œç•¢ã€‚")


# ========== 3. å»ºç«‹åœ–ç‰‡å‘é‡ ==========
def fetch_all_image_urls(cur):
    cur.execute("SELECT image_url FROM listing_images WHERE image_embedding IS NULL")
    urls = [row["image_url"] for row in cur.fetchall()]
    print(f"Found {len(urls)} images without embeddings.")
    return urls

def save_image_embedding(cur, conn, image_url, model, processor):
    try:
        image = Image.open(requests.get(image_url, stream=True).raw)
        inputs = processor(images=image, return_tensors="pt")

        with torch.no_grad():
            embedding = model.get_image_features(**inputs)
            embedding = embedding / embedding.norm(p=2, dim=-1)

        vector = embedding[0].tolist()

        cur.execute("""
            UPDATE listing_images
            SET image_embedding = %s
            WHERE image_url = %s
        """, (vector, image_url))
        conn.commit()
        print(f"âœ… Embedded: {image_url}")
    except Exception as e:
        print(f"âŒ Failed on {image_url}: {e}")


# ========== main ==========
if __name__ == "__main__":
    try:
        # æ¸¬è©¦ DB æ˜¯å¦å¯ç”¨
        cur.execute("SELECT NOW();")
        print("âœ… DB Connected. Current timestamp:", cur.fetchone()["now"])

        # 1. å»ºç«‹ listing æè¿°
        generate_listing_texts(cur, conn)

        # 2. å»ºç«‹åœ–ç‰‡ embedding
        model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32")
        processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")

        for image_url in fetch_all_image_urls(cur):
            save_image_embedding(cur, conn, image_url, model, processor)

    finally:
        cur.close()
        conn.close()
        print("ğŸ”š Connection closed.")
